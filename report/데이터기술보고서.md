# 🛫 데이터 기술 보고서

![crawling gif](img/crawling.gif)

## 개요
- 프로젝트 이름: Flight Ticket
- 프로젝트 지속기간: 2024.04.01~2024.04.02
- 개발 언어: Python
- 멤버: 팀 (김가영, 김주화, 하승주)

## 팀 소개
| 분야 | 이름 | 포지션 |
| --- | --- | --- |
| 개발 | 김가영 | 🖥️ 크롤링 설계, 깃 연동, 데이터베이스 연동 |
| 개발 | 김주화 | 💻 크롤링 설계, 깃 연동, 데이터베이스 연동 |
| 개발 | 하승주 | 🖥️ 크롤링 설계, 깃 연동, 데이터베이스 연동 |

## 프로젝트 소개
### A. 주제
✈️**항공권 크롤링**✈️
### B. 동기 및 목적
- 코로나 팬데믹 종식 이후 해외로 여행을 떠나는 여행객이 많아지고 체감 물가지수가 높아지면서, 좀더 저렴한 항공권을 찾는 소비자들이 많아졌다.
- 소비자들이 항공권을 쉽게 비교하고 합리적인 소비를 하기 위한 항공권 정보를 제공한다. 

### C. 이용 계획
- 데이터를 활용하여 여행사들이 여행상품을 만드는 데에 참고.
- 운항 횟수가 많은 노선을 파악하여 여행지 고객선호도, 시장분석 및 트렌드를 파악

## 후기
  ### 김가영🐰
  >처음에는 '크롤링만 성공하자', 성공하고 나니 'DB 연결만 해보자', 그다음에는 '좀 더 세분화되고 유익한 정보를 줄 수 있지 않을까' 하는 '도전'과 '성공', '고민'의 연속으로 저희 프로젝트는 진행되었습니다. <br> selenium과 webdriver를 이용하여 동적 크롤링를 진행하고 실행 결과를 확인했지만, 아쉬운 점은 '너무 느리다'는 것이었고, 이를 보완하기 위해 이후 Requests를 이용하여 정적 크롤링을 시도하고자 합니다. 또한, 사용자의 입력 결과에 따른 동적 데이터 수집이 저희 크롤링 프로젝트의 차별점이라고 생각하기 때문에 이후 검색과 검색 내역을 조회할 수 있는 GUI를 설계하고 구현하고자 합니다. <br> 협업에 있어서는 Git Branch 전략 3가지 중 Centralized Workflow 방식으로 진행했는데 단순하지만, 충돌을 방지하며 효율적인 코드 관리가 되었다고 생각합니다. 앞으로의 프로젝트에서 깃헙의 다양한 협업 방식을 따르면서 깃헙을 통한 협업에 익숙해 지고자 합니다.

  ### 김주화🐈
  >처음 진행해본 프로젝트라 시작을 어떻게 해야할지 감도 잡을 수가 없었다. 함께 고민하며 크롤링을 위한 코드를 짜보고 또 그 크롤링한 데이터에서 원하는 값만 추출해내는 작업이 제일 어렵고, 고민도, 시도도 많이 했던 것 같다. 원하는 데이터의 요소를 찾았지만 그 요소를 코드에 적용하는 일 또한 쉽지 않았다. 제일 어이없었던 실수는 개발자도구에서 뽑아낸 데이터가 XPATH 값을 넣어야 하는 자리에 select값을 넣는다던가 하는 일이었다. 같은 데이터이지만 여러가지의 언어로 나타낼 수 있고, 데이터를 뽑아낼 때 사용하는 언어들이 다르기 때문에 데이터를 삽입할 때 제일 유념해두어야 하는 부분인 것 같다. 사실 원하는 데이터를 추출해내는 일은 생각보다 어렵지 않은 일이지만 모르는 상태에서 진행하다보니 어떤 코드를 어떻게 적용해야할지 몰라서 많이 헤매고 찾아봤다. 그리고 그게 가장 도움되는 일이기도 했다. 내가 원하는 작업을 해내는 데에 쓸 수 있는 여러가지 코드들이 있고 그 존재를 알았다는 것만으로도 공부가 되지 않았나 싶다. 다른 조원들이 세심하게 작업해주어서 디테일한 부분도 가져갈 수 있었고 배울 수 있는 계기가 있어서 좋은 경험이었다

  ### 하승주🐈‍⬛
  >웹크롤링 프로젝트였지만, 크롤링에서부터 sql까지 수업 내용을 전반적으로 적용해볼 수 있었습니다. 정해진 조건의 항공권만 크롤링하는 것이 아니라 사용자가 선택한 출발/도착 공항과 날짜대로 정보를 조회할 수 있도록 자동검색을 구현 하는 것이 까다로웠지만 selenium의 다양한 메소드를 직접 적용해볼 수 있어 흥미로웠습니다. 또한 항공권 정보 페이지에서 원하는 요소만 긁어 데이터 프레임으로 만드는 것이 쉽지 않았지만 조원들과 의논하며 selector 및 코드 구조를 수정해보며 문제를 해결할 수 있었습니다. 본 프로젝트를 통해 수업에서 배운 파이썬과 sql, 웹크롤링 내용을 복습할 수 있었고, 특히 pymysql과 sql 연동에 대한 지식이 부족하다고 생각되어 보충하고 싶습니다. 시간이 많이 소요되는 selenium 크롤링의 단점을 보완하기 위하여 항공권 조회 페이지로 넘어간 후에는 해당 url을 전달받아 async와 request, beuatifulsoup을 활용해 비동기적으로 빠르게 정적 크롤링되도록 시도해보고 싶습니다. 
